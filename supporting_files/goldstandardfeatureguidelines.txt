Just-in-Time Tool Selection System Implementation Guide

  Overview and Motivation

  Current API usage consumes excessive context window space by providing all tools with every request. By implementing a dynamic tool selection system, we aim to:

  - Reduce token usage
  - Improve response time by selecting only relevant tools
  - Create a self-learning system that improves over time
  - Maintain full functionality through fallback mechanisms

  This document provides a step-by-step implementation plan for developers.

  System Architecture

  Components

  1. ToolSelector - Analyzes user messages and selects relevant tools
  2. ToolFinderTool - Meta-tool enabling LLM to request missing tools
  3. ToolMetrics - Tracks selection accuracy and performance metrics

  Integration Points

  - ToolRepository - Add selection functionality and initialize components
  - Conversation.generate_response() - Use selected tools instead of all tools
  - System prompt - Add tool_finder explanation

  Detailed Implementation Plan

  Phase 1: Core Selector Implementation

  Step 1: Create ToolSelector Class

  # tools/selector.py
  class ToolSelector:
      def __init__(self, storage_path=None):
          # Initialize storage location
          # Load existing data or create defaults
          # Set up keyword mappings, tool usage counters, etc.

      def select_tools(self, message, all_tools, min_tools=3, max_tools=7):
          # Select tools based on message content
          # Include essential tools, keyword matches, recent tools
          # Return list of selected tool names

      def record_usage(self, tool_name, was_selected=True):
          # Update usage statistics
          # Track if tool was in initial selection
          # Add frequently-missed tools to essential list

      def _load_data(self):
          # Load persistent data from disk

      def _save_data(self):
          # Save learning data to disk

  Key Features:
  - Keyword mapping dictionary (words -> relevant tools)
  - Essential tools list (always included)
  - Recent tools tracking (last N used)
  - Usage frequency tracking
  - Miss detection and learning

  Data Persistence:
  - Store in persistent/tool_selector_data.json
  - Format:
  {
    "essential_tools": ["help", "tool_finder"],
    "keyword_map": {"save": ["persistence"], "extract": ["extract_data"]},
    "tool_usage": {"persistence": 42, "extract_data": 17},
    "recent_tools": ["persistence", "extract_data", "check_task"],
    "tool_misses": {"extract_data": 2}
  }

  Step 2: Create ToolFinderTool

  # tools/tool_finder.py
  class ToolFinderTool:
      def __init__(self, tool_repo):
          self.tool_repo = tool_repo
          self.tool_summaries = self._generate_tool_summaries()

      def run(self, tool_name=None, description=None):
          # If specific tool requested, return its definition
          # If description provided, find matching tools
          # Otherwise return list of available tools
          # Record "misses" when tools were requested

      def _generate_tool_summaries(self):
          # Create concise summaries of all tools for matching

  Integration:
  - Register as a standard tool in ToolRepository
  - Always include in essential tools list
  - Ensure it can access all tools regardless of selection

  Step 3: Create ToolMetrics

  # tools/metrics.py
  class ToolMetrics:
      def __init__(self, storage_path=None):
          # Initialize metrics storage

      def record_tool_selection(self, message, selected_tools, all_tools):
          # Record how many tools were selected vs. available
          # Calculate estimated token savings

      def record_tool_usage(self, tool_name, was_in_selection):
          # Track how often selected tools were actually used
          # Track tools that had to be requested via tool_finder

      def record_response_time(self, seconds):
          # Track response time metrics

      def generate_report(self):
          # Produce summary metrics report

  Metrics to Track:
  - Selection accuracy (% of used tools that were pre-selected)
  - Miss rate (% of used tools that had to be requested)
  - Context savings (estimated tokens saved)
  - Response time impact

  Phase 2: Repository Integration

  Step 4: Update ToolRepository

  # Additions to tools/repo.py
  class ToolRepository:
      def __init__(self, ...):
          # Add initialization for selector and metrics
          self.selector = None
          self.metrics = None

      def _discover_and_initialize_tools(self):
          # Add initialization for selector, metrics, and tool_finder

      def select_tools_for_message(self, message, min_tools=3, max_tools=7):
          # Use selector to choose relevant tools
          # Return tool definitions for selected tools
          # Record selection metrics

  Error Handling:
  - Graceful fallback to all tools if selector fails
  - Exception handling for metrics recording

  Phase 3: Conversation Integration

  Step 5: Update Conversation Flow

  # Update in conversation.py
  def generate_response(self, user_input, ...):
      # Start response time tracking
      start_time = time.time()

      # For initial message, use selected tools
      if tool_iterations == 0:
          selected_tools = self.tool_repo.select_tools_for_message(user_input)
      else:
          # For subsequent iterations, use all tools
          selected_tools = self.tool_repo.get_all_tool_definitions()

      # Generate LLM response with selected tools
      response = self.llm_provider.generate_response(
          messages=messages,
          system_prompt=self.system_prompt,
          tools=selected_tools,  # Use selected tools here
          ...
      )

      # Record tool usage in _process_tool_calls method

      # Record response time
      if hasattr(self.tool_repo, 'metrics'):
          end_time = time.time()
          self.tool_repo.metrics.record_response_time(end_time - start_time)

  Step 6: Update System Prompt

  Add to system prompt:
  TOOL FINDER:
  If you need a tool that isn't currently available to you, use the tool_finder tool:
  - To request a specific tool: <tool>tool_finder(tool_name="persistence")</tool>
  - To find tools by description: <tool>tool_finder(description="I need to save data")</tool>
  The tool_finder will give you the definition of requested tools or suggest relevant tools based on your description.

  Phase 4: Testing and Validation

  Step 7: Test Implementation

  1. Compare token usage with and without selector
  2. Verify tool finder successfully retrieves missing tools
  3. Test selector learning by tracking frequently missed tools
  4. Validate metrics reporting

  Step 8: Optimize Selection Parameters

  - Adjust minimum/maximum tool counts
  - Tune keyword mappings based on usage patterns
  - Optimize essential tools list

  Edge Cases and Error Handling

  1. Missing Data File
    - Create default settings on first run
    - Document default keyword mappings
  2. Unknown Tools
    - Allow selector to safely ignore unknown tools
    - Validate against available tools before returning
  3. Selection Failures
    - Fall back to full tool set if selection fails
    - Log errors but continue operation
  4. Persistence Errors
    - Continue operation even if data can't be saved/loaded
    - Recreate defaults if data is corrupted

  Future Extension Points

  1. ML-Based Selection
    - Add TF-IDF or Naive Bayes classifier for better matching
    - Implement incremental learning from usage patterns
  2. Contextual Analysis
    - Analyze conversation history for better tool prediction
    - Consider conversation topic for tool selection
  3. Performance Optimization
    - Add caching for frequent user queries
    - Pre-compute common selection patterns

  Performance Expectations

  - Expected token reduction
  - Response time improvement
  - Learning effectiveness

  This implementation provides an incremental path to significant performance improvements while maintaining full functionality through the tool finder fallback mechanism. Now that you have an implementation guide I want you to ultrathink about the actual code that will be required. The changes should naturally dovetail into the existing codebase. If you run into any severe conflicts or need clarification please just ask me, I'll guide you.
